{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bayes Theorem and Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bayes' theorem describes how to update the probability of a hypothesis based on new evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p(x | y, \\theta) = \\frac{p(y | x, \\theta) p(x | \\theta)}{p(y | \\theta)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where,\n",
    "- $y$: observations\n",
    "- $\\theta$: parameters (latent variables)\n",
    "- $x$: state of the system, quantity of interest\n",
    "\n",
    "Therefore, \n",
    "\n",
    "- $p(\\theta)$ is the prior distribution of the parameters\n",
    "- $p(y | x, \\theta)$ is the likelihood of the observations\n",
    "- $p(x | y, \\theta)$ is the generative model, it is the posterior distribution\n",
    "- $p (y | \\theta)$ is a normalisation constant, also known as marginal likelihood or evidence. Model evidence can be used for Bayesian model selection. \n",
    "\n",
    "The posterior $p(x | y, \\theta)$ is the updated probability of the hypothesis $x$ given the observed evidence $y$. The likelihood $p(y | x, \\theta)$ represents the probability of observig the evidence $y$ assuming the hypothesis $x$ and parameters $\\theta$ are true. The prior $p(x | \\theta)$ reflects the initial belief about $x$ before any data $y$ is observed. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
